{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from wordcloud import WordCloud\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import ensemble\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data frame\n",
    "recipe_df = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20052 entries, 0 to 20051\n",
      "Columns: 680 entries, title to turkey\n",
      "dtypes: float64(679), object(1)\n",
      "memory usage: 104.0+ MB\n",
      "                                         title  rating  calories  protein  \\\n",
      "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
      "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
      "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
      "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
      "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
      "\n",
      "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
      "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
      "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
      "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
      "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
      "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
      "\n",
      "   ...  yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  \\\n",
      "0  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
      "1  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
      "2  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
      "3  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
      "4  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
      "\n",
      "   snack  snack week  turkey  \n",
      "0    0.0         0.0     1.0  \n",
      "1    0.0         0.0     0.0  \n",
      "2    0.0         0.0     0.0  \n",
      "3    0.0         0.0     0.0  \n",
      "4    0.0         0.0     0.0  \n",
      "\n",
      "[5 rows x 680 columns] None              rating      calories        protein           fat        sodium  \\\n",
      "count  20052.000000  1.593500e+04   15890.000000  1.586900e+04  1.593300e+04   \n",
      "mean       3.714467  6.322958e+03     100.160793  3.468775e+02  6.225975e+03   \n",
      "std        1.340829  3.590460e+05    3840.318527  2.045611e+04  3.333182e+05   \n",
      "min        0.000000  0.000000e+00       0.000000  0.000000e+00  0.000000e+00   \n",
      "25%        3.750000  1.980000e+02       3.000000  7.000000e+00  8.000000e+01   \n",
      "50%        4.375000  3.310000e+02       8.000000  1.700000e+01  2.940000e+02   \n",
      "75%        4.375000  5.860000e+02      27.000000  3.300000e+01  7.110000e+02   \n",
      "max        5.000000  3.011122e+07  236489.000000  1.722763e+06  2.767511e+07   \n",
      "\n",
      "          #cakeweek    #wasteless  22-minute meals  3-ingredient recipes  \\\n",
      "count  20052.000000  20052.000000     20052.000000          20052.000000   \n",
      "mean       0.000299      0.000050         0.000848              0.001346   \n",
      "std        0.017296      0.007062         0.029105              0.036671   \n",
      "min        0.000000      0.000000         0.000000              0.000000   \n",
      "25%        0.000000      0.000000         0.000000              0.000000   \n",
      "50%        0.000000      0.000000         0.000000              0.000000   \n",
      "75%        0.000000      0.000000         0.000000              0.000000   \n",
      "max        1.000000      1.000000         1.000000              1.000000   \n",
      "\n",
      "       30 days of groceries  ...  yellow squash        yogurt       yonkers  \\\n",
      "count          20052.000000  ...   20052.000000  20052.000000  20052.000000   \n",
      "mean               0.000349  ...       0.001247      0.026332      0.000050   \n",
      "std                0.018681  ...       0.035288      0.160123      0.007062   \n",
      "min                0.000000  ...       0.000000      0.000000      0.000000   \n",
      "25%                0.000000  ...       0.000000      0.000000      0.000000   \n",
      "50%                0.000000  ...       0.000000      0.000000      0.000000   \n",
      "75%                0.000000  ...       0.000000      0.000000      0.000000   \n",
      "max                1.000000  ...       1.000000      1.000000      1.000000   \n",
      "\n",
      "               yuca      zucchini     cookbooks     leftovers         snack  \\\n",
      "count  20052.000000  20052.000000  20052.000000  20052.000000  20052.000000   \n",
      "mean       0.000299      0.014861      0.000150      0.000349      0.001396   \n",
      "std        0.017296      0.121001      0.012231      0.018681      0.037343   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "         snack week        turkey  \n",
      "count  20052.000000  20052.000000  \n",
      "mean       0.000948      0.022741  \n",
      "std        0.030768      0.149080  \n",
      "min        0.000000      0.000000  \n",
      "25%        0.000000      0.000000  \n",
      "50%        0.000000      0.000000  \n",
      "75%        0.000000      0.000000  \n",
      "max        1.000000      1.000000  \n",
      "\n",
      "[8 rows x 679 columns]\n"
     ]
    }
   ],
   "source": [
    "#examine the data frame\n",
    "\n",
    "print(\n",
    "    recipe_df.head(),\n",
    "    recipe_df.info(),\n",
    "    recipe_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df2 = recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turkey            0.0\n",
       "fortified wine    0.0\n",
       "frittata          0.0\n",
       "friendsgiving     0.0\n",
       "freezer food      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "\n",
    "missing_values_ratios = (recipe_df2.isnull().sum()/recipe_df2.isnull().count())\n",
    "missing_values_ratios.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15864.000000\n",
       "mean         3.760952\n",
       "std          1.285518\n",
       "min          0.000000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_df2['rating2']=recipe_df2['rating']\n",
    "\n",
    "recipe_df.rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating2           1.000000\n",
       "drink             0.229547\n",
       "alcoholic         0.209148\n",
       "house & garden    0.199738\n",
       "gin               0.184992\n",
       "spirit            0.135300\n",
       "cocktail          0.131203\n",
       "bon appétit       0.129069\n",
       "bitters           0.127979\n",
       "cocktail party    0.125811\n",
       "harpercollins     0.100491\n",
       "non-alcoholic     0.081777\n",
       "rum               0.080409\n",
       "peanut free       0.078845\n",
       "soy free          0.078212\n",
       "condiment         0.076352\n",
       "roast             0.071724\n",
       "bake              0.070332\n",
       "tree nut free     0.069766\n",
       "liqueur           0.066126\n",
       "fall              0.065290\n",
       "chartreuse        0.064081\n",
       "weelicious        0.063155\n",
       "créme de cacao    0.063103\n",
       "sauté             0.061349\n",
       "thanksgiving      0.060912\n",
       "brandy            0.059976\n",
       "fortified wine    0.059934\n",
       "winter            0.058439\n",
       "vermouth          0.058122\n",
       "pickles           0.058081\n",
       "Name: rating2, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the correlation of the numerical variables with the target\n",
    "np.abs(recipe_df2[recipe_df2.select_dtypes('float64').columns].iloc[:,1:].corr().loc[:,\"rating2\"]).sort_values(ascending=False).head(31)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a binary version of the target\n",
    "rating_binary = []\n",
    "\n",
    "for idx, val in enumerate(recipe_df2['rating2']):\n",
    "    if val >= 3.5:\n",
    "        rating_binary.append(1)\n",
    "    else:\n",
    "        rating_binary.append(0)\n",
    "        \n",
    "recipe_df2['rating_binary'] = rating_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(recipe_df2[['drink', 'alcoholic', 'house & garden', 'gin',\n",
    "                                             'spirit', 'cocktail', 'bon appétit', 'bitters', 'cocktail party',\n",
    "                                             'harpercollins', 'non-alcoholic', 'rum', 'peanut free', 'soy free',\n",
    "                                             'condiment', 'roast', 'bake', 'tree nut free', 'liqueur', 'fall',\n",
    "                                             'chartreuse', 'weelicious', 'créme de cacao', 'sauté', 'thanksgiving',\n",
    "                                             'brandy', 'fortified wine', 'winter', 'vermouth', 'pickles']])\n",
    "\n",
    "\n",
    "Y = recipe_df2.rating_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = np.arange(0, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_pca = [{'pca__n_components':n_comps}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree_pca = make_pipeline(PCA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pca = GridSearchCV(pipe_tree_pca, param_grid=param_grid_pca, cv=10)\n",
    "\n",
    "#gs_pca.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 29}\n"
     ]
    }
   ],
   "source": [
    "gs_pca.fit(X,Y)\n",
    "print(gs_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components=29)\n",
    "X_sklearn = sklearn_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_sklearn, Y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = [{'svc__degree':degrees}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tree_svm = make_pipeline(SVC(kernel = 'poly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm = GridSearchCV(pipe_tree_svm, param_grid=param_grid_svm, cv=10)\n",
    "\n",
    "#gs_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__degree': 2}\n"
     ]
    }
   ],
   "source": [
    "gs_svm.fit(X_train,Y_train)\n",
    "print(gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='poly',degree=2)\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the predictions for analysis\n",
    "Y_pred = svm.fit(X_train, Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8338558  0.82075472 0.8170347  0.829653   0.81072555 0.829653\n",
      " 0.82018927 0.79179811 0.82018927 0.80757098]\n",
      "The 10-fold cross validation average for the testing set  is  0.8181424396480356\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm, X_test, Y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(svm, X_test, Y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
