{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from wordcloud import WordCloud\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import neighbors\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import ensemble\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_events_df = (pd.read_csv('Data/talkingdata/app_events.csv'))\n",
    "\n",
    "app_labels_df = (pd.read_csv('Data/talkingdata/app_labels.csv'))\n",
    "\n",
    "events_df = (pd.read_csv('Data/talkingdata/events.csv'))\n",
    "\n",
    "gender_age_test_df = (pd.read_csv('Data/talkingdata/gender_age_test.csv'))\n",
    "\n",
    "gender_age_train_df = (pd.read_csv('Data/talkingdata/gender_age_train.csv'))\n",
    "\n",
    "label_categories_df = (pd.read_csv('Data/talkingdata/label_categories.csv'))\n",
    "\n",
    "phone_brand_device_model_df = (pd.read_csv('Data/talkingdata/phone_brand_device_model.csv'))\n",
    "\n",
    "sample_submission_df = (pd.read_csv('Data/talkingdata/sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_events = app_events_df\n",
    "df_app_labels = app_labels_df\n",
    "df_events = events_df\n",
    "df_gender_age_test = gender_age_test_df\n",
    "df_gender_age_train = gender_age_train_df\n",
    "df_label_categories = label_categories_df\n",
    "df_phone_brand_device_model = phone_brand_device_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32473067 entries, 0 to 32473066\n",
      "Data columns (total 4 columns):\n",
      "event_id        int64\n",
      "app_id          int64\n",
      "is_installed    int64\n",
      "is_active       int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 991.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    app_events_df.head(),\n",
    "    app_events_df.info(),\n",
    "#    app_events_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app_events_df['event_id'].value_counts()\n",
    "\n",
    "#NTS: turn event_id and app_id into top 20 or so bar graphs (or histograms?) (line graph?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459943 entries, 0 to 459942\n",
      "Data columns (total 2 columns):\n",
      "app_id      459943 non-null int64\n",
      "label_id    459943 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 7.0 MB\n",
      "                app_id  label_id\n",
      "0  7324884708820027918       251\n",
      "1 -4494216993218550286       251\n",
      "2  6058196446775239644       406\n",
      "3  6058196446775239644       407\n",
      "4  8694625920731541625       406\n",
      "5  8694625920731541625       407\n",
      "6  1977658975649789753       406\n",
      "7  1977658975649789753       407\n",
      "8  7311663864768030840       256\n",
      "9  5902120154267999338       256 None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    app_labels_df.head(10),\n",
    "    app_labels_df.info(),\n",
    "#    app_labels_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app_labels_df['label_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3252950 entries, 0 to 3252949\n",
      "Data columns (total 5 columns):\n",
      "event_id     int64\n",
      "device_id    int64\n",
      "timestamp    object\n",
      "longitude    float64\n",
      "latitude     float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 124.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    events_df.head(),\n",
    "    events_df.info(),\n",
    "#    events_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_df['event_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74645 entries, 0 to 74644\n",
      "Data columns (total 4 columns):\n",
      "device_id    74645 non-null int64\n",
      "gender       74645 non-null object\n",
      "age          74645 non-null int64\n",
      "group        74645 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    gender_age_train_df.head(),\n",
    "    gender_age_train_df.info(),\n",
    "#    gender_age_train_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender_age_train_df['device_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112071 entries, 0 to 112070\n",
      "Data columns (total 1 columns):\n",
      "device_id    112071 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 875.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    gender_age_test_df.head(),\n",
    "    gender_age_test_df.info(),\n",
    "#    gender_age_test_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 930 entries, 0 to 929\n",
      "Data columns (total 2 columns):\n",
      "label_id    930 non-null int64\n",
      "category    927 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    label_categories_df.head(),\n",
    "    label_categories_df.info(),\n",
    "#    label_categories_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187245 entries, 0 to 187244\n",
      "Data columns (total 3 columns):\n",
      "device_id       187245 non-null int64\n",
      "phone_brand     187245 non-null object\n",
      "device_model    187245 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "#    phone_brand_device_model_df.head(),\n",
    "    phone_brand_device_model_df.info(),\n",
    "#    phone_brand_device_model_df.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phone_brand_device_model['encoded_model'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phone_brand_device_model['encoded_model'] = df_phone_brand_device_model['device_model'].apply(lambda x: x.encode('unicode-escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.encode('unicode-escape')\n",
    "#.encode(encoding=\"utf-8\", errors=\"strict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(app_events_df, app_labels_df, events_df, gender_age_test_df, gender_age_train_df,\n",
    "   label_categories_df, phone_brand_device_model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 91.01103711128235 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "apps_labeled = pd.merge(df_app_labels,\n",
    "                       df_app_events[['app_id', 'is_active']],\n",
    "                       on='app_id').dropna().drop_duplicates()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 38.64483714103699 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "device_apps = pd.merge(df_events,\n",
    "                       df_app_events[['app_id', 'is_active', 'event_id']],\n",
    "                       on='event_id').dropna().drop_duplicates()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.294361114501953 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ga_apps = pd.merge(df_gender_age_train,\n",
    "                  device_apps[['app_id', 'is_active', 'device_id']],\n",
    "                  on='device_id').dropna().drop_duplicates()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.5375468730926514 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ga_apps_brands = pd.merge(ga_apps,\n",
    "                         df_phone_brand_device_model[['device_id', 'encoded_model']],\n",
    "                         on='device_id').dropna().drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17.529872179031372 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ga_apps_labeled_brands = pd.merge(ga_apps_brands,\n",
    "                                 apps_labeled[['app_id', 'label_id']],\n",
    "                                 on='app_id').dropna().drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_app_events, df_app_labels, df_events, df_gender_age_test, df_gender_age_train, df_label_categories,\n",
    "   df_phone_brand_device_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert gender into a binary output\n",
    "ga_apps_labeled_brands['gender'] = ga_apps_labeled_brands['gender'].apply(lambda x: 1 if x == 'M' else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7034350 entries, 0 to 13874875\n",
      "Data columns (total 8 columns):\n",
      "device_id        int64\n",
      "gender           int64\n",
      "age              int64\n",
      "group            object\n",
      "app_id           int64\n",
      "is_active        int64\n",
      "encoded_model    object\n",
      "label_id         int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 483.0+ MB\n"
     ]
    }
   ],
   "source": [
    "ga_apps_labeled_brands.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dummy variables from the object variables\n",
    "start_time = time.time()\n",
    "\n",
    "ga_apps_labeled_brands_dums = pd.concat([ga_apps_labeled_brands, pd.get_dummies(\n",
    "    ga_apps_labeled_brands[['encoded_model']], drop_first=True)], axis=1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the correlation of various features with the target\n",
    "\n",
    "np.abs(ga_apps_labeled_brands[\n",
    "    ga_apps_labeled_brands.select_dtypes([\n",
    "        'int64', 'float64']).columns].iloc[:,1:].corr().loc[:,'gender']).sort_values(ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ga_apps_labeled_brands.select_dtypes(['int64', 'float64']).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([ga_apps_labeled_brands[['device_id', 'app_id', 'is_active', 'label_id']], ga_apps_labeled_brands_dums.select_dtypes(['uint8'])], axis=1, sort=False)\n",
    "             \n",
    "y = ga_apps_labeled_brands['gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = np.arange(50)\n",
    "param_grid_pca = [{'pca__n_components':n_comps}]\n",
    "pipe_tree_pca = make_pipeline(PCA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pca = GridSearchCV(pipe_tree_pca, param_grid=param_grid_pca, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pca.fit(X_norm,y)\n",
    "print(gs_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the results of GridSearchCV to perform PCA\n",
    "\n",
    "sklearn_pca = PCA(n_components=300)  \n",
    "X_pca = sklearn_pca.fit_transform(X_norm)\n",
    "\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA:\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "#X_pca is now our PCA engineered feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into four equally-sized samples for analysis with silhouette. \n",
    "X_half1, X_half2, X_pcahalf1, X_pcahalf2 = train_test_split(\n",
    "    X_norm,\n",
    "    X_pca,\n",
    "    test_size=0.5,\n",
    "    random_state=42)\n",
    "X1, X2, X_pca1, X_pca2 = train_test_split(\n",
    "    X_half1,\n",
    "    X_pcahalf1,\n",
    "    test_size=0.5,\n",
    "    random_state=42)\n",
    "X3, X4, X_pca3, X_pca4 = train_test_split(\n",
    "    X_half2,\n",
    "    X_pcahalf2,\n",
    "    test_size=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca,\n",
    "    y,\n",
    "    test_size=0.1,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ga_apps_labeled_brands, ga_apps_labeled_brands_dums, ga_apps_brands, ga_apps, device_apps, apps_labeled\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in [X_pca1, X_pca2, X_pca3, X_pca4]:\n",
    "    model = KMeans(n_clusters=4, random_state=42).fit(sample)\n",
    "    labels_test = model.labels_\n",
    "    print(metrics.silhouette_score(sample, labels_test, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in [X_pca1, X_pca2, X_pca3, X_pca4]:\n",
    "    model = KMeans(n_clusters=5, random_state=42).fit(sample)\n",
    "    labels_test = model.labels_\n",
    "    print(metrics.silhouette_score(sample, labels_test, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in [X_pca1, X_pca2, X_pca3, X_pca4]:\n",
    "    model = KMeans(n_clusters=6, random_state=42).fit(sample)\n",
    "    labels_test = model.labels_\n",
    "    print(metrics.silhouette_score(sample, labels_test, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette analysis seems relatively ambivalent to the number of clusters from 4-6. We will try six clusters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=6).fit(X_train)\n",
    "labels = y_pred.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_train, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up parameters for GridSearchCV(DecisionTreeClassifier())\n",
    "\n",
    "depths = np.arange(1, 25)\n",
    "num_features = [1, 2]\n",
    "\n",
    "param_grid_dt_pca = [{'decisiontreeclassifier__max_depth':depths,\n",
    "               'decisiontreeclassifier__max_features':num_features}]\n",
    "\n",
    "pipe_tree_dt_pca = make_pipeline(tree.DecisionTreeClassifier(criterion='entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt_pca = GridSearchCV(pipe_tree_dt_pca, param_grid=param_grid_dt_pca, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decisiontreeclassifier__max_depth': 1, 'decisiontreeclassifier__max_features': 1}\n"
     ]
    }
   ],
   "source": [
    "gs_dt_pca.fit(X_train,y_train)\n",
    "print(gs_dt_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train the decision tree model using GridSearchCV results\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=2,\n",
    "    max_depth=1\n",
    ")\n",
    "\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "y_pred_dt = decision_tree.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(decision_tree, X_train, y_train, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(decision_tree, X_train, y_train, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(decision_tree, X_test, y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(decision_tree, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_dt, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(y_test, y_pred_dt, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification reports, a value of 1 corresponds to a value of \"late\" for the target variable \"delay\", and 0 corresponds to a \"on-time.\"  Although decision tree models tend to handle varied types of data well, this model isn't achieving any useful discrimination of the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "y_preds_rfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(rfc, X_train, y_train, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(rfc, X_train, y_train, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(rfc, X_test, y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(rfc, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(y_test, y_preds_rfc, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(y_test, y_preds_rfc, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the decision tree model, the random forest model is not a good fit for this data.  It was unable to discriminate the target variable whatsoever with this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1,2]\n",
    "param_grid_svm = [{'svc__degree':degrees}]\n",
    "pipe_tree_svm = make_pipeline(SVC(kernel = 'poly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm = GridSearchCV(pipe_tree_svm, param_grid=param_grid_svm, cv=10)\n",
    "\n",
    "#gs_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "gs_svm.fit(X_train,y_train)\n",
    "print(gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=1, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='poly',degree=1)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the predictions for analysis\n",
    "y_pred_svm = svm.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(svm, X_train, y_train, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(svm, X_train, y_train, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51049815 0.51049815 0.51049815 0.51029654 0.51029654 0.51029654\n",
      " 0.51029654 0.5105068  0.5105068  0.5105068 ]\n",
      "The 10-fold cross validation average for the testing set  is  0.510420099915708\n",
      "--- 204.898530960083 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(svm, X_test, y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(svm, X_test, y_test, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68     12393\n",
      "           1       0.00      0.00      0.00     11887\n",
      "\n",
      "    accuracy                           0.51     24280\n",
      "   macro avg       0.26      0.50      0.34     24280\n",
      "weighted avg       0.26      0.51      0.34     24280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[12393     0]\n",
      " [11887     0]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(y_test, y_pred_svm, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the decision tree and random forest models above, the SVM model was completely unable to classify the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_preds_nb = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(bnb, X_train, y_train, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(bnb, X_train, y_train, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(bnb, X_test, y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(bnb, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(y_test, y_preds_nb, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(y_test, y_preds_nb, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "num_neighbors = np.arange(1, 25)\n",
    "weights = ['distance','uniform']\n",
    "leaf_sizes = np.arange(1, 40)\n",
    "\n",
    "param_grid_knn = [{'kneighborsclassifier__n_neighbors':num_neighbors,\n",
    "                      'kneighborsclassifier__weights':weights,\n",
    "                      'kneighborsclassifier__leaf_size':leaf_sizes}\n",
    "                     ]\n",
    "pipe_tree_knn = make_pipeline(neighbors.KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_knn = GridSearchCV(pipe_tree_knn, param_grid=param_grid_knn, cv=10)\n",
    "\n",
    "#gs_knn.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kneighborsclassifier__leaf_size': 4, 'kneighborsclassifier__n_neighbors': 21, 'kneighborsclassifier__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "gs_knn.fit(X_train,y_train)\n",
    "print(gs_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'kneighborsclassifier__leaf_size': 29, 'kneighborsclassifier__n_neighbors': 1, 'kneighborsclassifier__weights': 'distance'}\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=21, weights='distance', leaf_size=4)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify, storing the result in a new variable.\n",
    "y_preds_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(knn, X_train, y_train, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(knn, X_train, y_train, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(knn, X_test, y_test, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(knn, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(y_test, y_preds_knn, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(y_test, y_preds_knn, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
