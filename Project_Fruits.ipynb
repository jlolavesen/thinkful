{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from wordcloud import WordCloud\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import neighbors\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import ensemble\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This amazing dataset contains tens of thousands of carefully curated images of 120 different fruits.\n",
    "- It can be found here: https://www.kaggle.com/moltean/fruits\n",
    "- Let's build some neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, Conv3D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25.87718415260315 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#import the data\n",
    "start_time = time.time()\n",
    "\n",
    "train_dir = 'Data/fruits-360_dataset/fruits-360/Training' \n",
    "test_dir = 'Data/fruits-360_dataset/fruits-360/Test'\n",
    "\n",
    "def load_dataset(path): \n",
    "    data = load_files(path) \n",
    "    files = np.array(data['filenames']) \n",
    "    targets = np.array(data['target']) \n",
    "    target_labels = np.array(data['target_names']) \n",
    "    return files,targets,target_labels\n",
    "\n",
    "x_train, y_train, target_labels = load_dataset(train_dir) \n",
    "x_test, y_test,_ = load_dataset(test_dir)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 28.49203395843506 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#convert image files to matrices\n",
    "start_time = time.time()\n",
    "\n",
    "x_train_mat = []\n",
    "x_test_mat = []\n",
    "\n",
    "for img in x_train:\n",
    "    n= cv2.imread(img)\n",
    "    x_train_mat.append(n)\n",
    "\n",
    "for img in x_test:\n",
    "    n= cv2.imread(img)\n",
    "    x_test_mat.append(n)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.8697540760040283 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#convert data to numpy arrays\n",
    "start_time = time.time()\n",
    "\n",
    "x_train_matnp = np.array(x_train_mat)\n",
    "x_test_matnp = np.array(x_test_mat)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.32676196098327637 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "del(x_train_mat, x_test_mat)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_matnp shape: (60498, 100, 100, 3)\n",
      "60498 train samples\n",
      "20622 test samples\n",
      "--- 32.652241230010986 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#reshape and normalize data\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "img_rows, img_cols = 100, 100\n",
    "num_classes = 120\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train_matnp = x_train_matnp.reshape(x_train_matnp.shape[0], 3, img_rows, img_cols)\n",
    "    x_test_matnp = x_test_matnp.reshape(x_test_matnp.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train_matnp = x_train_matnp.reshape(x_train_matnp.shape[0], img_rows, img_cols, 3)\n",
    "    x_test_matnp = x_test_matnp.reshape(x_test_matnp.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train_matnp = x_train_matnp.astype('float32')\n",
    "x_test_matnp = x_test_matnp.astype('float32')\n",
    "x_train_matnp /= 255\n",
    "x_test_matnp /= 255\n",
    "print('x_train_matnp shape:', x_train_matnp.shape)\n",
    "print(x_train_matnp.shape[0], 'train samples')\n",
    "print(x_test_matnp.shape[0], 'test samples')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train)\n",
    "y_test_cat = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               15480     \n",
      "=================================================================\n",
      "Total params: 4,735,416\n",
      "Trainable params: 4,735,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60498 samples, validate on 20622 samples\n",
      "Epoch 1/10\n",
      "60498/60498 [==============================] - 281s 5ms/step - loss: 1.9492 - accuracy: 0.4961 - val_loss: 0.4462 - val_accuracy: 0.8770\n",
      "Epoch 2/10\n",
      "60498/60498 [==============================] - 274s 5ms/step - loss: 0.5179 - accuracy: 0.8352 - val_loss: 0.2333 - val_accuracy: 0.9291\n",
      "Epoch 3/10\n",
      "60498/60498 [==============================] - 271s 4ms/step - loss: 0.3004 - accuracy: 0.9000 - val_loss: 0.1740 - val_accuracy: 0.9483\n",
      "Epoch 4/10\n",
      "60498/60498 [==============================] - 270s 4ms/step - loss: 0.2255 - accuracy: 0.9242 - val_loss: 0.1693 - val_accuracy: 0.9530\n",
      "Epoch 5/10\n",
      "60498/60498 [==============================] - 271s 4ms/step - loss: 0.1860 - accuracy: 0.9367 - val_loss: 0.1596 - val_accuracy: 0.9572\n",
      "Epoch 6/10\n",
      "60498/60498 [==============================] - 270s 4ms/step - loss: 0.1642 - accuracy: 0.9450 - val_loss: 0.1738 - val_accuracy: 0.9541\n",
      "Epoch 7/10\n",
      "60498/60498 [==============================] - 274s 5ms/step - loss: 0.1469 - accuracy: 0.9512 - val_loss: 0.1476 - val_accuracy: 0.9600\n",
      "Epoch 8/10\n",
      "60498/60498 [==============================] - 271s 4ms/step - loss: 0.1326 - accuracy: 0.9555 - val_loss: 0.1537 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "60498/60498 [==============================] - 270s 4ms/step - loss: 0.1259 - accuracy: 0.9584 - val_loss: 0.1654 - val_accuracy: 0.9575\n",
      "Epoch 10/10\n",
      "60498/60498 [==============================] - 267s 4ms/step - loss: 0.1161 - accuracy: 0.9618 - val_loss: 0.1597 - val_accuracy: 0.9595\n",
      "Test loss: 0.159725972155145\n",
      "Test accuracy: 0.9594607949256897\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_matnp, y_train_cat,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_matnp, y_test_cat))\n",
    "score = model.evaluate(x_test_matnp, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 96, 96, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 120)               15480     \n",
      "=================================================================\n",
      "Total params: 9,455,224\n",
      "Trainable params: 9,455,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_2.add(Dropout(0.25))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(128, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60498 samples, validate on 20622 samples\n",
      "Epoch 1/10\n",
      "60498/60498 [==============================] - 691s 11ms/step - loss: 2.8145 - accuracy: 0.2980 - val_loss: 0.7175 - val_accuracy: 0.8101\n",
      "Epoch 2/10\n",
      "60498/60498 [==============================] - 504s 8ms/step - loss: 0.9764 - accuracy: 0.6894 - val_loss: 0.3444 - val_accuracy: 0.9027\n",
      "Epoch 3/10\n",
      "60498/60498 [==============================] - 488s 8ms/step - loss: 0.6031 - accuracy: 0.8006 - val_loss: 0.2442 - val_accuracy: 0.9309\n",
      "Epoch 4/10\n",
      "60498/60498 [==============================] - 487s 8ms/step - loss: 0.4702 - accuracy: 0.8429 - val_loss: 0.2369 - val_accuracy: 0.9341\n",
      "Epoch 5/10\n",
      "60498/60498 [==============================] - 486s 8ms/step - loss: 0.4062 - accuracy: 0.8645 - val_loss: 0.1974 - val_accuracy: 0.9423\n",
      "Epoch 6/10\n",
      "60498/60498 [==============================] - 481s 8ms/step - loss: 0.3641 - accuracy: 0.8789 - val_loss: 0.1633 - val_accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "60498/60498 [==============================] - 481s 8ms/step - loss: 0.3285 - accuracy: 0.8895 - val_loss: 0.1602 - val_accuracy: 0.9552\n",
      "Epoch 8/10\n",
      "60498/60498 [==============================] - 481s 8ms/step - loss: 0.3163 - accuracy: 0.8930 - val_loss: 0.1694 - val_accuracy: 0.9568\n",
      "Epoch 9/10\n",
      "60498/60498 [==============================] - 480s 8ms/step - loss: 0.2972 - accuracy: 0.8999 - val_loss: 0.1756 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "60498/60498 [==============================] - 482s 8ms/step - loss: 0.2802 - accuracy: 0.9033 - val_loss: 0.1435 - val_accuracy: 0.9649\n",
      "Test loss: 0.14352463840097535\n",
      "Test accuracy: 0.9649403691291809\n"
     ]
    }
   ],
   "source": [
    "model_2.fit(x_train_matnp, y_train_cat,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_matnp, y_test_cat))\n",
    "score = model_2.evaluate(x_test_matnp, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                2359360   \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 2,368,376\n",
      "Trainable params: 2,368,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Conv2D(16, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Dropout(0.25))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60498 samples, validate on 20622 samples\n",
      "Epoch 1/10\n",
      "60498/60498 [==============================] - 261s 4ms/step - loss: 3.6771 - accuracy: 0.1376 - val_loss: 1.4257 - val_accuracy: 0.6813\n",
      "Epoch 2/10\n",
      "60498/60498 [==============================] - 247s 4ms/step - loss: 1.8365 - accuracy: 0.4465 - val_loss: 0.5829 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "60498/60498 [==============================] - 250s 4ms/step - loss: 1.4253 - accuracy: 0.5450 - val_loss: 0.5865 - val_accuracy: 0.8416\n",
      "Epoch 4/10\n",
      "60498/60498 [==============================] - 249s 4ms/step - loss: 1.2184 - accuracy: 0.6004 - val_loss: 0.3490 - val_accuracy: 0.9110\n",
      "Epoch 5/10\n",
      "60498/60498 [==============================] - 248s 4ms/step - loss: 1.0725 - accuracy: 0.6432 - val_loss: 0.3155 - val_accuracy: 0.9103\n",
      "Epoch 6/10\n",
      "60498/60498 [==============================] - 247s 4ms/step - loss: 0.9843 - accuracy: 0.6707 - val_loss: 0.4131 - val_accuracy: 0.8952\n",
      "Epoch 7/10\n",
      "60498/60498 [==============================] - 246s 4ms/step - loss: 0.9263 - accuracy: 0.6858 - val_loss: 0.2841 - val_accuracy: 0.9249\n",
      "Epoch 8/10\n",
      "60498/60498 [==============================] - 247s 4ms/step - loss: 0.8982 - accuracy: 0.6944 - val_loss: 0.2866 - val_accuracy: 0.9253\n",
      "Epoch 9/10\n",
      "60498/60498 [==============================] - 251s 4ms/step - loss: 0.8788 - accuracy: 0.7006 - val_loss: 0.2570 - val_accuracy: 0.9326\n",
      "Epoch 10/10\n",
      "60498/60498 [==============================] - 248s 4ms/step - loss: 0.8521 - accuracy: 0.7093 - val_loss: 0.2780 - val_accuracy: 0.9281\n",
      "Test loss: 0.27795652542980437\n",
      "Test accuracy: 0.928086519241333\n"
     ]
    }
   ],
   "source": [
    "model_3.fit(x_train_matnp, y_train_cat,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_matnp, y_test_cat))\n",
    "score = model_3.evaluate(x_test_matnp, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 96, 96, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4718656   \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 4,728,888\n",
      "Trainable params: 4,728,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "model_4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_4.add(Dropout(0.25))\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(64, activation='relu'))\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_4.summary()\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60498 samples, validate on 20622 samples\n",
      "Epoch 1/10\n",
      "60498/60498 [==============================] - 380s 6ms/step - loss: 2.2664 - accuracy: 0.4100 - val_loss: 0.5725 - val_accuracy: 0.8525\n",
      "Epoch 2/10\n",
      "60498/60498 [==============================] - 373s 6ms/step - loss: 0.8001 - accuracy: 0.7434 - val_loss: 0.3499 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "60498/60498 [==============================] - 372s 6ms/step - loss: 0.5399 - accuracy: 0.8202 - val_loss: 0.2247 - val_accuracy: 0.9370\n",
      "Epoch 4/10\n",
      "60498/60498 [==============================] - 372s 6ms/step - loss: 0.4363 - accuracy: 0.8517 - val_loss: 0.2256 - val_accuracy: 0.9384\n",
      "Epoch 5/10\n",
      "60498/60498 [==============================] - 372s 6ms/step - loss: 0.3751 - accuracy: 0.8703 - val_loss: 0.2294 - val_accuracy: 0.9442\n",
      "Epoch 6/10\n",
      "60498/60498 [==============================] - 371s 6ms/step - loss: 0.3436 - accuracy: 0.8805 - val_loss: 0.2276 - val_accuracy: 0.9357\n",
      "Epoch 7/10\n",
      "60498/60498 [==============================] - 374s 6ms/step - loss: 0.3189 - accuracy: 0.8911 - val_loss: 0.1913 - val_accuracy: 0.9487\n",
      "Epoch 8/10\n",
      "60498/60498 [==============================] - 374s 6ms/step - loss: 0.2911 - accuracy: 0.8991 - val_loss: 0.2219 - val_accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "60498/60498 [==============================] - 371s 6ms/step - loss: 0.2812 - accuracy: 0.9027 - val_loss: 0.2331 - val_accuracy: 0.9467\n",
      "Epoch 10/10\n",
      "60498/60498 [==============================] - 375s 6ms/step - loss: 0.2715 - accuracy: 0.9061 - val_loss: 0.1840 - val_accuracy: 0.9572\n",
      "Test loss: 0.1839948054649649\n",
      "Test accuracy: 0.9572301506996155\n"
     ]
    }
   ],
   "source": [
    "model_4.fit(x_train_matnp, y_train_cat,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_matnp, y_test_cat))\n",
    "score = model_4.evaluate(x_test_matnp, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 16)        1216      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 92, 92, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2166848   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 2,182,280\n",
      "Trainable params: 2,182,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Conv2D(16, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)))\n",
    "model_5.add(Conv2D(16, (5, 5), activation='relu'))\n",
    "model_5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_5.add(Dropout(0.25))\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(64, activation='relu'))\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_5.summary()\n",
    "\n",
    "model_5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60498 samples, validate on 20622 samples\n",
      "Epoch 1/10\n",
      "60498/60498 [==============================] - 976s 16ms/step - loss: 3.3373 - accuracy: 0.1975 - val_loss: 0.8474 - val_accuracy: 0.7997\n",
      "Epoch 2/10\n",
      "60498/60498 [==============================] - 881s 15ms/step - loss: 1.3542 - accuracy: 0.5865 - val_loss: 0.3829 - val_accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "60498/60498 [==============================] - 990s 16ms/step - loss: 0.8692 - accuracy: 0.7185 - val_loss: 0.2295 - val_accuracy: 0.9282\n",
      "Epoch 4/10\n",
      "60498/60498 [==============================] - 1028s 17ms/step - loss: 0.6821 - accuracy: 0.7765 - val_loss: 0.2150 - val_accuracy: 0.9346\n",
      "Epoch 5/10\n",
      "60498/60498 [==============================] - 1014s 17ms/step - loss: 0.5727 - accuracy: 0.8088 - val_loss: 0.2136 - val_accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "60498/60498 [==============================] - 891s 15ms/step - loss: 0.5204 - accuracy: 0.8261 - val_loss: 0.2217 - val_accuracy: 0.9378\n",
      "Epoch 7/10\n",
      "60498/60498 [==============================] - 940s 16ms/step - loss: 0.4801 - accuracy: 0.8391 - val_loss: 0.1586 - val_accuracy: 0.9545\n",
      "Epoch 8/10\n",
      "60498/60498 [==============================] - 1004s 17ms/step - loss: 0.4526 - accuracy: 0.8478 - val_loss: 0.1652 - val_accuracy: 0.9578\n",
      "Epoch 9/10\n",
      "60498/60498 [==============================] - 977s 16ms/step - loss: 0.4300 - accuracy: 0.8557 - val_loss: 0.1894 - val_accuracy: 0.9481\n",
      "Epoch 10/10\n",
      "60498/60498 [==============================] - 930s 15ms/step - loss: 0.4200 - accuracy: 0.8566 - val_loss: 0.1678 - val_accuracy: 0.9563\n",
      "Test loss: 0.1678199889935895\n",
      "Test accuracy: 0.9563087821006775\n"
     ]
    }
   ],
   "source": [
    "model_5.fit(x_train_matnp, y_train_cat,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_matnp, y_test_cat))\n",
    "score = model_5.evaluate(x_test_matnp, y_test_cat, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, the models with the best accuracy have more complexity and more trainable parameters, meaning that they are more resource intensive and take longer to learn.  There are so many trade-offs an options with these models, it seems as thouh one could easily spend an entire career or more optimizing them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
