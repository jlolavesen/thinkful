{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import normaltest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from wordcloud import WordCloud\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "import pydotplus\n",
    "from sklearn import ensemble\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign data frame\n",
    "df_telco = (pd.read_excel('Data/Telco_Churn.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      "customerID          7043 non-null object\n",
      "gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null object\n",
      "Dependents          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns] None        SeniorCitizen       tenure  MonthlyCharges\n",
      "count    7043.000000  7043.000000     7043.000000\n",
      "mean        0.162147    32.371149       64.761692\n",
      "std         0.368612    24.559481       30.090047\n",
      "min         0.000000     0.000000       18.250000\n",
      "25%         0.000000     9.000000       35.500000\n",
      "50%         0.000000    29.000000       70.350000\n",
      "75%         0.000000    55.000000       89.850000\n",
      "max         1.000000    72.000000      118.750000\n"
     ]
    }
   ],
   "source": [
    "#examine the data frame\n",
    "\n",
    "print(\n",
    "    df_telco.head(),\n",
    "    df_telco.info(),\n",
    "    df_telco.describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_telco.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco.TotalCharges=pd.to_numeric(df_telco.TotalCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TotalCharges      0.001562\n",
       "Churn             0.000000\n",
       "OnlineSecurity    0.000000\n",
       "gender            0.000000\n",
       "SeniorCitizen     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "\n",
    "missing_values_ratios = (df_telco.isnull().sum()/df_telco.isnull().count())\n",
    "missing_values_ratios.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn             0.0\n",
       "OnlineSecurity    0.0\n",
       "gender            0.0\n",
       "SeniorCitizen     0.0\n",
       "Partner           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_ratios = (df_telco.isnull().sum()/df_telco.isnull().count())\n",
    "missing_values_ratios.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_telco = pd.concat([df_telco,pd.get_dummies(\n",
    "    df_telco[['gender','Partner','Dependents','PhoneService','MultipleLines','InternetService',\n",
    "                'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV',\n",
    "                'StreamingMovies','Contract','PaperlessBilling','PaymentMethod']], drop_first=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a boolean version of the target for algorithmic friendliness\n",
    "churn_bool = []\n",
    "\n",
    "for idx, val in enumerate(df_telco['Churn']):\n",
    "    if val == 'Yes':\n",
    "        churn_bool.append(1)\n",
    "    else:\n",
    "        churn_bool.append(0)\n",
    "        \n",
    "df_telco['churn_bool'] = churn_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn_bool                               1.000000\n",
       "tenure                                   0.354049\n",
       "InternetService_Fiber optic              0.307463\n",
       "Contract_Two year                        0.301552\n",
       "PaymentMethod_Electronic check           0.301455\n",
       "StreamingTV_No internet service          0.227578\n",
       "InternetService_No                       0.227578\n",
       "OnlineSecurity_No internet service       0.227578\n",
       "DeviceProtection_No internet service     0.227578\n",
       "TechSupport_No internet service          0.227578\n",
       "OnlineBackup_No internet service         0.227578\n",
       "StreamingMovies_No internet service      0.227578\n",
       "TotalCharges                             0.199484\n",
       "MonthlyCharges                           0.192858\n",
       "PaperlessBilling_Yes                     0.191454\n",
       "Contract_One year                        0.178225\n",
       "OnlineSecurity_Yes                       0.171270\n",
       "TechSupport_Yes                          0.164716\n",
       "Dependents_Yes                           0.163128\n",
       "Partner_Yes                              0.149982\n",
       "PaymentMethod_Credit card (automatic)    0.134687\n",
       "PaymentMethod_Mailed check               0.090773\n",
       "OnlineBackup_Yes                         0.082307\n",
       "DeviceProtection_Yes                     0.066193\n",
       "StreamingTV_Yes                          0.063254\n",
       "StreamingMovies_Yes                      0.060860\n",
       "MultipleLines_Yes                        0.040033\n",
       "PhoneService_Yes                         0.011691\n",
       "MultipleLines_No phone service           0.011691\n",
       "gender_Male                              0.008545\n",
       "Name: churn_bool, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the correlation of various features with the target\n",
    "\n",
    "np.abs(df_telco[df_telco.select_dtypes(['int64', 'float64', 'uint8']).columns].iloc[:,1:].corr().loc[:,'churn_bool']).sort_values(ascending=False).head(35)\n",
    "\n",
    "#NTS: the ^above^ logic fails if the target is categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INCLUDE HERE! correlation map of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning features\n",
    "\n",
    "#X is standardized\n",
    "X = StandardScaler().fit_transform(pd.concat([df_telco[['SeniorCitizen','tenure','MonthlyCharges','TotalCharges']], \n",
    "                                              df_telco.select_dtypes(['uint8'])], axis=1, sort=False)\n",
    "                                  )\n",
    "\n",
    "#XX is the same data as X but not standardized\n",
    "XX = pd.concat([df_telco[['SeniorCitizen','tenure','MonthlyCharges','TotalCharges']], \n",
    "                df_telco.select_dtypes(['uint8'])], axis=1, sort=False\n",
    "              )\n",
    "\n",
    "#Y is the target\n",
    "Y = df_telco.churn_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NTS: these functions are useful diagnostic tools\n",
    "\n",
    "#np.isinf(X).any()\n",
    "#np.isinf(Y).any()\n",
    "\n",
    "#np.isnan(X).any()\n",
    "#np.isnan(Y).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up parameters for GridSearchCV(X)... the plan is PCA(GridSearchCV(X))\n",
    "\n",
    "n_comps = np.arange(0, 25)\n",
    "param_grid_pca = [{'pca__n_components':n_comps}]\n",
    "pipe_tree_pca = make_pipeline(PCA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pca = GridSearchCV(pipe_tree_pca, param_grid=param_grid_pca, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 22}\n"
     ]
    }
   ],
   "source": [
    "gs_pca.fit(X,Y)\n",
    "print(gs_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA:\n",
      " [0.33160138 0.12009062 0.09014536 0.04754993 0.04143011 0.04120627\n",
      " 0.03815289 0.03336784 0.03123044 0.02954298 0.02659613 0.02379643\n",
      " 0.02249445 0.02055908 0.02024829 0.01748569 0.01555265 0.01525414\n",
      " 0.01467132 0.00923412 0.00784362 0.00191635]\n"
     ]
    }
   ],
   "source": [
    "#using the results of GridSearchCV to perform PCA\n",
    "\n",
    "sklearn_pca = PCA(n_components=22)  \n",
    "X_pca = sklearn_pca.fit_transform(X)\n",
    "\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA:\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "#X_pca is now our PCA engineered feature set.\n",
    "#NTS: try a feature set applying PCA to the four numerical variables and adding the raw uint8 features separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SelectKBest contrasts with PCA as a feature selection tool\n",
    "\n",
    "selection = SelectKBest(score_func=f_regression, k='all') \n",
    "X_kbest = selection.fit(XX, Y).transform(XX)\n",
    "\n",
    "#we can compare the performance of models with a PCA derived feature set (X_pca(X)),\n",
    "#    vs a SelectKBest derived feature set (X_kbest(XX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into testing and training sets\n",
    "X_train_skb, X_test_skb, Y_train_skb, Y_test_skb = train_test_split(\n",
    "    X_kbest, Y, test_size = 0.20, random_state = 1\n",
    ")\n",
    "\n",
    "X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(\n",
    "    X_pca, Y, test_size = 0.20, random_state = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Decision Tree(SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up parameters for GridSearchCV(DecisionTreeClassifier())\n",
    "\n",
    "depths = np.arange(1, 25)\n",
    "num_features = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "param_grid_dt_skb = [{'decisiontreeclassifier__max_depth':depths,\n",
    "               'decisiontreeclassifier__max_features':num_features}]\n",
    "\n",
    "pipe_tree_dt_skb = make_pipeline(tree.DecisionTreeClassifier(criterion='entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt_skb = GridSearchCV(pipe_tree_dt_skb, param_grid=param_grid_dt_skb, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decisiontreeclassifier__max_depth': 6, 'decisiontreeclassifier__max_features': 7}\n"
     ]
    }
   ],
   "source": [
    "gs_dt_skb.fit(X_train_skb,Y_train_skb)\n",
    "print(gs_dt_skb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize and train the decision tree model using GridSearchCV results\n",
    "#    {'decisiontreeclassifier__max_depth': 6, 'decisiontreeclassifier__max_features': 7}\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=7,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "decision_tree.fit(X_train_skb, Y_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "Y_pred_dt = decision_tree.fit(X_train_skb, Y_train_skb).predict(X_test_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78900709 0.78723404 0.78152753 0.79715302 0.76868327 0.79003559\n",
      " 0.78469751 0.76868327 0.78291815 0.77580071]\n",
      "The 10-fold cross validation average for the training set is  0.7752786448222126\n",
      "--- 0.6514401435852051 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(decision_tree, X_train_skb, Y_train_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(decision_tree, X_train_skb, Y_train_skb, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78873239 0.75177305 0.71631206 0.78723404 0.76595745 0.75177305\n",
      " 0.76428571 0.78571429 0.77142857 0.75714286]\n",
      "The 10-fold cross validation average for the testing set  is  0.761233642992708\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(decision_tree, X_test_skb, Y_test_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(decision_tree, X_test_skb, Y_test_skb, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1041\n",
      "           1       0.61      0.50      0.55       366\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1407\n",
      "   macro avg       0.72      0.69      0.70      1407\n",
      "weighted avg       0.77      0.79      0.78      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_skb, Y_pred_dt, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[923 118]\n",
      " [184 182]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_skb, Y_pred_dt, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Decision Tree(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up parameters for GridSearchCV(DecisionTreeClassifier())\n",
    "\n",
    "depths = np.arange(1, 25)\n",
    "num_features = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "param_grid_dt_pca = [{'decisiontreeclassifier__max_depth':depths,\n",
    "               'decisiontreeclassifier__max_features':num_features}]\n",
    "\n",
    "pipe_tree_dt_pca = make_pipeline(tree.DecisionTreeClassifier(criterion='entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_dt_pca = GridSearchCV(pipe_tree_dt_pca, param_grid=param_grid_dt_pca, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decisiontreeclassifier__max_depth': 4, 'decisiontreeclassifier__max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "gs_dt_pca.fit(X_train_pca,Y_train_pca)\n",
    "print(gs_dt_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
       "            max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize and train the decision tree model using GridSearchCV results\n",
    "#    {'decisiontreeclassifier__max_depth': 4, 'decisiontreeclassifier__max_features': 8}\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=4,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "decision_tree.fit(X_train_pca, Y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "Y_pred_dt_pca = decision_tree.fit(X_train_pca, Y_train_pca).predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75886525 0.79255319 0.76198934 0.78647687 0.77224199 0.75978648\n",
      " 0.77935943 0.75266904 0.77402135 0.77402135]\n",
      "The 10-fold cross validation average for the training set is  0.7688871607773172\n",
      "--- 0.5928928852081299 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(decision_tree, X_train_pca, Y_train_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(decision_tree, X_train_pca, Y_train_pca, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72535211 0.74468085 0.72340426 0.78723404 0.75886525 0.75177305\n",
      " 0.78571429 0.75       0.78571429 0.72142857]\n",
      "The 10-fold cross validation average for the testing set  is  0.7534015440158683\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(decision_tree, X_test_pca, Y_test_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(decision_tree, X_test_pca, Y_test_pca, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      1041\n",
      "           1       0.54      0.42      0.47       366\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1407\n",
      "   macro avg       0.67      0.65      0.66      1407\n",
      "weighted avg       0.74      0.76      0.75      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_pca, Y_pred_dt_pca, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[963  78]\n",
      " [232 134]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_pca, Y_pred_dt_pca, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest Classifier(SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train_skb,Y_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "Y_preds_rfc_skb=rfc.predict(X_test_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7712766  0.75       0.76376554 0.78469751 0.76512456 0.77402135\n",
      " 0.78291815 0.76156584 0.76512456 0.77935943]\n",
      "The 10-fold cross validation average for the training set is  0.7701415460780414\n",
      "--- 2.888967990875244 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(rfc, X_train_skb, Y_train_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(rfc, X_train_skb, Y_train_skb, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77464789 0.76595745 0.73758865 0.77304965 0.82269504 0.75886525\n",
      " 0.78571429 0.75       0.8        0.75714286]\n",
      "The 10-fold cross validation average for the testing set  is  0.7804281718680879\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(rfc, X_test_skb, Y_test_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(rfc, X_test_skb, Y_test_skb, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      1041\n",
      "           1       0.58      0.41      0.48       366\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1407\n",
      "   macro avg       0.69      0.65      0.66      1407\n",
      "weighted avg       0.75      0.77      0.75      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_skb, Y_preds_rfc_skb, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[932 109]\n",
      " [217 149]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_skb, Y_preds_rfc_skb, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Random Forest Classifier(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc.fit(X_train_pca,Y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions for model evaluation\n",
    "Y_preds_rfc_pca=rfc.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77836879 0.7748227  0.75666075 0.79181495 0.76512456 0.75978648\n",
      " 0.78291815 0.7633452  0.77935943 0.79003559]\n",
      "The 10-fold cross validation average for the training set is  0.7688953612566097\n",
      "--- 3.2938950061798096 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(rfc, X_train_pca, Y_train_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(rfc, X_train_pca, Y_train_pca, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76760563 0.72340426 0.75177305 0.78014184 0.80851064 0.75886525\n",
      " 0.77142857 0.77857143 0.86428571 0.8       ]\n",
      "The 10-fold cross validation average for the testing set  is  0.771932374388173\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(rfc, X_test_pca, Y_test_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(rfc, X_test_pca, Y_test_pca, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      1041\n",
      "           1       0.59      0.40      0.47       366\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1407\n",
      "   macro avg       0.70      0.65      0.66      1407\n",
      "weighted avg       0.75      0.77      0.75      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_pca, Y_preds_rfc_pca, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[939 102]\n",
      " [221 145]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_pca, Y_preds_rfc_pca, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: SVM(SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4]\n",
    "param_grid_svm_skb = [{'svc__degree':degrees}]\n",
    "pipe_tree_svm_skb = make_pipeline(SVC(kernel = 'poly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm = GridSearchCV(pipe_tree_svm_skb, param_grid=param_grid_svm_skb, cv=10)\n",
    "\n",
    "#gs_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "gs_svm.fit(X_train_skb,Y_train_skb)\n",
    "print(gs_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='poly',degree=1)\n",
    "svm.fit(X_train_skb, Y_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the predictions for analysis\n",
    "Y_pred_svm_skb = svm.fit(X_train_skb, Y_train_skb).predict(X_test_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80851064 0.80319149 0.79040853 0.81672598 0.78825623 0.80960854\n",
      " 0.82206406 0.79359431 0.78825623 0.79181495]\n",
      "The 10-fold cross validation average for the training set is  0.8012430938111967\n",
      "--- 8.648271083831787 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(svm, X_train_skb, Y_train_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(svm, X_train_skb, Y_train_skb, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76760563 0.73049645 0.78014184 0.80851064 0.78723404 0.78014184\n",
      " 0.8        0.79285714 0.85714286 0.75      ]\n",
      "The 10-fold cross validation average for the testing set  is  0.7854130456497852\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(svm, X_test_skb, Y_test_skb, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(svm, X_test_skb, Y_test_skb, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1041\n",
      "           1       0.62      0.54      0.58       366\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1407\n",
      "   macro avg       0.73      0.71      0.72      1407\n",
      "weighted avg       0.79      0.79      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_skb, Y_pred_svm_skb, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[919 122]\n",
      " [169 197]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_skb, Y_pred_svm_skb, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: SVM(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [1, 2, 3, 4]\n",
    "param_grid_svm_pca = [{'svc__degree':degrees}]\n",
    "pipe_tree_svm_pca = make_pipeline(SVC(kernel = 'poly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm_pca = GridSearchCV(pipe_tree_svm_pca, param_grid=param_grid_svm_pca, cv=10)\n",
    "\n",
    "#gs_svm.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "gs_svm_pca.fit(X_train_pca,Y_train_pca)\n",
    "print(gs_svm_pca.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=1, gamma='auto_deprecated',\n",
       "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='poly',degree=1)\n",
    "svm.fit(X_train_pca, Y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the predictions for analysis\n",
    "Y_pred_svm_pca = svm.fit(X_train_pca, Y_train_pca).predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80851064 0.80319149 0.79040853 0.81672598 0.78825623 0.80960854\n",
      " 0.82206406 0.79359431 0.78825623 0.79181495]\n",
      "The 10-fold cross validation average for the training set is  0.8012430938111967\n",
      "--- 9.206144571304321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the training set\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(cross_val_score(svm, X_train_pca, Y_train_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the training set is ', \n",
    "      cross_val_score(svm, X_train_pca, Y_train_pca, cv=10).mean())\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76760563 0.73049645 0.78014184 0.80851064 0.78723404 0.78014184\n",
      " 0.8        0.79285714 0.85714286 0.75      ]\n",
      "The 10-fold cross validation average for the testing set  is  0.7854130456497852\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model performance through xvalidation of the testing set\n",
    "\n",
    "print(cross_val_score(svm, X_test_pca, Y_test_pca, cv=10))\n",
    "print('The 10-fold cross validation average for the testing set  is ', \n",
    "      cross_val_score(svm, X_test_pca, Y_test_pca, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1041\n",
      "           1       0.62      0.54      0.58       366\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1407\n",
      "   macro avg       0.73      0.71      0.72      1407\n",
      "weighted avg       0.79      0.79      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "\n",
    "print(classification_report(Y_test_pca, Y_pred_svm_pca, labels=None, target_names=None, \n",
    "                      sample_weight=None, digits=2, output_dict=False\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set confusion matrix: \n",
      " [[919 122]\n",
      " [169 197]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "print('Test set confusion matrix:', '\\n', \n",
    "      confusion_matrix(Y_test_pca, Y_pred_svm_pca, labels=None, sample_weight=None)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
